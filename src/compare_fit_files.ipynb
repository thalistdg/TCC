{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tqdm\n",
    "\n",
    "from fitter import Fitter\n",
    "from scipy.stats import exponnorm, erlang, gennorm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(column):\n",
    "    stream = []\n",
    "    days = range(1, 23) # 1, 32\n",
    "    months = range(1, 2) #1, 3\n",
    "    for month in months:\n",
    "        month_2_digits = '{month:02}'.format(month=month)\n",
    "        path = '../COVID19_Tweets_Dataset_2020/Summary_Sentiment/2020_' + month_2_digits + '/'\n",
    "\n",
    "        for day in days:\n",
    "            if month == 2 and day > 29:\n",
    "                continue\n",
    "            if month == 1 and day < 22:\n",
    "                continue\n",
    "\n",
    "            for hour in range(24): # 24\n",
    "                file_name = path + f'2020_{month_2_digits}_' + '{day:02}'.format(day=day) + '_{hour:02}'.format(hour=hour) + '_Summary_Sentiment.csv'\n",
    "                stream.append(pd.read_csv(file_name)[column])\n",
    "\n",
    "    return pd.concat(stream, ignore_index=True), stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "stream_ln, tweets_per_file = load_data('Logits_Negative')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fitted_summary(data):\n",
    "    f = Fitter(data)\n",
    "    f.distributions = f.distributions[:3]\n",
    "    f.fit()\n",
    "    return f.summary(method='ks_pvalue', plot=False, clf=False, Nbest=110)['ks_pvalue'].values\n",
    "\n",
    "\n",
    "def process_dist_ks_values():\n",
    "    dist_ks_values = []\n",
    "    n_tweets = 0\n",
    "    n_files = 0\n",
    "    for tweets_hour in tqdm.tqdm(tweets_per_file):\n",
    "        n_files += 1\n",
    "        n_tweets += len(tweets_hour)\n",
    "        dist_ks_values.append(get_fitted_summary(tweets_hour))\n",
    "        # for i, row in table.iterrows():\n",
    "        #     if i in dist_ks_values:\n",
    "        #         dist_ks_values[i].append(row['ks_pvalue'])\n",
    "        #     else:\n",
    "        #         dist_ks_values[i] = [row['ks_pvalue']]\n",
    "\n",
    "        if n_files % 24 == 0:\n",
    "            pd.DataFrame(dist_ks_values).to_pickle('../results/compare_fit_files_day_{}.pkl'.format(n_files//24))\n",
    "            dist_ks_values = []\n",
    "\n",
    "    if len(dist_ks_values) > 0:\n",
    "        pd.DataFrame(dist_ks_values).to_pickle('../results/compare_fit_files_day_{}.pkl'.format(n_files/24))\n",
    "\n",
    "    print(f'Processed {len(tweets_per_file)} files!')\n",
    "    print(f'Processed {len(tweets_per_file)//24} days!')\n",
    "    print(f'Processed {n_tweets} tweets!')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/24 [00:00<?, ?it/s]SKIPPED _fit distribution (taking more than 30 seconds)\n",
      "Fitting 3 distributions: 100%|██████████| 3/3 [00:00<00:00, 44.86it/s]\n",
      "SKIPPED _fit distribution (taking more than 30 seconds)\n",
      "Fitting 3 distributions: 100%|██████████| 3/3 [00:00<00:00, 32.71it/s]\n",
      "  8%|▊         | 2/24 [00:00<00:02, 10.64it/s]SKIPPED _fit distribution (taking more than 30 seconds)\n",
      "Fitting 3 distributions: 100%|██████████| 3/3 [00:00<00:00, 31.07it/s]\n",
      "SKIPPED _fit distribution (taking more than 30 seconds)\n",
      "Fitting 3 distributions: 100%|██████████| 3/3 [00:00<00:00, 38.02it/s]\n",
      " 17%|█▋        | 4/24 [00:00<00:01, 10.09it/s]SKIPPED _fit distribution (taking more than 30 seconds)\n",
      "Fitting 3 distributions: 100%|██████████| 3/3 [00:00<00:00, 47.28it/s]\n",
      "SKIPPED _fit distribution (taking more than 30 seconds)\n",
      "Fitting 3 distributions: 100%|██████████| 3/3 [00:00<00:00, 39.01it/s]\n",
      " 25%|██▌       | 6/24 [00:00<00:01, 10.84it/s]SKIPPED _fit distribution (taking more than 30 seconds)\n",
      "Fitting 3 distributions: 100%|██████████| 3/3 [00:00<00:00, 41.52it/s]\n",
      "SKIPPED _fit distribution (taking more than 30 seconds)\n",
      "Fitting 3 distributions: 100%|██████████| 3/3 [00:00<00:00, 40.83it/s]\n",
      " 33%|███▎      | 8/24 [00:00<00:01, 11.16it/s]SKIPPED _fit distribution (taking more than 30 seconds)\n",
      "Fitting 3 distributions: 100%|██████████| 3/3 [00:00<00:00, 33.46it/s]\n",
      "SKIPPED _fit distribution (taking more than 30 seconds)\n",
      "Fitting 3 distributions: 100%|██████████| 3/3 [00:00<00:00, 33.68it/s]\n",
      " 42%|████▏     | 10/24 [00:00<00:01, 10.69it/s]SKIPPED _fit distribution (taking more than 30 seconds)\n",
      "Fitting 3 distributions: 100%|██████████| 3/3 [00:00<00:00, 28.57it/s]\n",
      "SKIPPED _fit distribution (taking more than 30 seconds)\n",
      "Fitting 3 distributions: 100%|██████████| 3/3 [00:00<00:00, 30.64it/s]\n",
      " 50%|█████     | 12/24 [00:01<00:01,  9.87it/s]SKIPPED _fit distribution (taking more than 30 seconds)\n",
      "Fitting 3 distributions: 100%|██████████| 3/3 [00:00<00:00, 27.26it/s]\n",
      "SKIPPED _fit distribution (taking more than 30 seconds)\n",
      "Fitting 3 distributions: 100%|██████████| 3/3 [00:00<00:00, 42.15it/s]\n",
      " 58%|█████▊    | 14/24 [00:01<00:01,  9.79it/s]SKIPPED _fit distribution (taking more than 30 seconds)\n",
      "Fitting 3 distributions: 100%|██████████| 3/3 [00:00<00:00, 23.48it/s]\n",
      " 62%|██████▎   | 15/24 [00:01<00:00,  9.14it/s]SKIPPED _fit distribution (taking more than 30 seconds)\n",
      "Fitting 3 distributions: 100%|██████████| 3/3 [00:00<00:00, 17.79it/s]\n",
      " 67%|██████▋   | 16/24 [00:01<00:01,  7.98it/s]SKIPPED _fit distribution (taking more than 30 seconds)\n",
      "Fitting 3 distributions: 100%|██████████| 3/3 [00:00<00:00, 19.83it/s]\n",
      " 71%|███████   | 17/24 [00:01<00:00,  7.43it/s]SKIPPED _fit distribution (taking more than 30 seconds)\n",
      "Fitting 3 distributions: 100%|██████████| 3/3 [00:00<00:00, 20.87it/s]\n",
      " 75%|███████▌  | 18/24 [00:02<00:00,  7.09it/s]SKIPPED _fit distribution (taking more than 30 seconds)\n",
      "Fitting 3 distributions: 100%|██████████| 3/3 [00:00<00:00, 38.97it/s]\n",
      "SKIPPED _fit distribution (taking more than 30 seconds)\n",
      "Fitting 3 distributions: 100%|██████████| 3/3 [00:00<00:00, 18.67it/s]\n",
      " 83%|████████▎ | 20/24 [00:02<00:00,  7.24it/s]SKIPPED _fit distribution (taking more than 30 seconds)\n",
      "Fitting 3 distributions: 100%|██████████| 3/3 [00:00<00:00, 18.07it/s]\n",
      " 88%|████████▊ | 21/24 [00:02<00:00,  6.74it/s]SKIPPED _fit distribution (taking more than 30 seconds)\n",
      "Fitting 3 distributions: 100%|██████████| 3/3 [00:00<00:00, 18.40it/s]\n",
      " 92%|█████████▏| 22/24 [00:02<00:00,  6.41it/s]SKIPPED _fit distribution (taking more than 30 seconds)\n",
      "Fitting 3 distributions: 100%|██████████| 3/3 [00:00<00:00, 17.37it/s]\n",
      " 96%|█████████▌| 23/24 [00:02<00:00,  6.08it/s]SKIPPED _fit distribution (taking more than 30 seconds)\n",
      "Fitting 3 distributions: 100%|██████████| 3/3 [00:00<00:00, 37.75it/s]\n",
      "100%|██████████| 24/24 [00:02<00:00,  8.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 24 files!\n",
      "Processed 1 days!\n",
      "Processed 36333 tweets!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "process_dist_ks_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1388888888888889"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pkls = []\n",
    "for p in range(1,2):\n",
    "    read_file = f'../results/compare_fit_files_day_{p}.pkl'\n",
    "    pkls.append(pd.read_pickle(read_file))\n",
    "df_ks_values = pd.concat(pkls, ignore_index=True)\n",
    "\n",
    "\n",
    "ks_list = []\n",
    "for _, i in df_ks_values.iterrows():\n",
    "    ks_list.append(i)\n",
    "\n",
    "np.mean([i>=.01 for i in np.concatenate(ks_list)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/24 [00:00<?, ?it/s]SKIPPED _fit distribution (taking more than 30 seconds)\n",
      "Fitting 3 distributions: 100%|██████████| 3/3 [00:00<00:00, 37.83it/s]\n",
      "SKIPPED _fit distribution (taking more than 30 seconds)\n",
      "Fitting 3 distributions: 100%|██████████| 3/3 [00:00<00:00, 33.38it/s]\n",
      "  8%|▊         | 2/24 [00:00<00:02, 10.23it/s]SKIPPED _fit distribution (taking more than 30 seconds)\n",
      "Fitting 3 distributions: 100%|██████████| 3/3 [00:00<00:00, 30.54it/s]\n",
      "SKIPPED _fit distribution (taking more than 30 seconds)\n",
      "Fitting 3 distributions: 100%|██████████| 3/3 [00:00<00:00, 23.99it/s]\n",
      " 17%|█▋        | 4/24 [00:00<00:02,  8.78it/s]SKIPPED _fit distribution (taking more than 30 seconds)\n",
      "Fitting 3 distributions: 100%|██████████| 3/3 [00:00<00:00, 45.19it/s]\n",
      "SKIPPED _fit distribution (taking more than 30 seconds)\n",
      "Fitting 3 distributions: 100%|██████████| 3/3 [00:00<00:00, 38.60it/s]\n",
      " 25%|██▌       | 6/24 [00:00<00:01,  9.83it/s]SKIPPED _fit distribution (taking more than 30 seconds)\n",
      "Fitting 3 distributions: 100%|██████████| 3/3 [00:00<00:00, 38.44it/s]\n",
      "SKIPPED _fit distribution (taking more than 30 seconds)\n",
      "Fitting 3 distributions: 100%|██████████| 3/3 [00:00<00:00, 44.78it/s]\n",
      " 33%|███▎      | 8/24 [00:00<00:01, 10.48it/s]SKIPPED _fit distribution (taking more than 30 seconds)\n",
      "Fitting 3 distributions: 100%|██████████| 3/3 [00:00<00:00, 31.35it/s]\n",
      "SKIPPED _fit distribution (taking more than 30 seconds)\n",
      "Fitting 3 distributions: 100%|██████████| 3/3 [00:00<00:00, 27.90it/s]\n",
      " 42%|████▏     | 10/24 [00:01<00:01,  9.69it/s]SKIPPED _fit distribution (taking more than 30 seconds)\n",
      "Fitting 3 distributions: 100%|██████████| 3/3 [00:00<00:00, 26.89it/s]\n",
      " 46%|████▌     | 11/24 [00:01<00:01,  9.22it/s]SKIPPED _fit distribution (taking more than 30 seconds)\n",
      "Fitting 3 distributions: 100%|██████████| 3/3 [00:00<00:00, 28.11it/s]\n",
      " 50%|█████     | 12/24 [00:01<00:01,  8.99it/s]SKIPPED _fit distribution (taking more than 30 seconds)\n",
      "Fitting 3 distributions: 100%|██████████| 3/3 [00:00<00:00, 29.21it/s]\n",
      " 54%|█████▍    | 13/24 [00:01<00:01,  8.87it/s]SKIPPED _fit distribution (taking more than 30 seconds)\n",
      "Fitting 3 distributions: 100%|██████████| 3/3 [00:00<00:00, 45.49it/s]\n",
      "SKIPPED _fit distribution (taking more than 30 seconds)\n",
      "Fitting 3 distributions: 100%|██████████| 3/3 [00:00<00:00, 23.32it/s]\n",
      " 62%|██████▎   | 15/24 [00:01<00:01,  8.89it/s]SKIPPED _fit distribution (taking more than 30 seconds)\n",
      "Fitting 3 distributions: 100%|██████████| 3/3 [00:00<00:00, 22.96it/s]\n",
      " 67%|██████▋   | 16/24 [00:01<00:00,  8.32it/s]SKIPPED _fit distribution (taking more than 30 seconds)\n",
      "Fitting 3 distributions: 100%|██████████| 3/3 [00:00<00:00, 22.43it/s]\n",
      " 71%|███████   | 17/24 [00:01<00:00,  7.85it/s]SKIPPED _fit distribution (taking more than 30 seconds)\n",
      "Fitting 3 distributions: 100%|██████████| 3/3 [00:00<00:00, 21.84it/s]\n",
      " 75%|███████▌  | 18/24 [00:02<00:00,  7.47it/s]SKIPPED _fit distribution (taking more than 30 seconds)\n",
      "Fitting 3 distributions: 100%|██████████| 3/3 [00:00<00:00, 41.07it/s]\n",
      "SKIPPED _fit distribution (taking more than 30 seconds)\n",
      "Fitting 3 distributions: 100%|██████████| 3/3 [00:00<00:00, 19.55it/s]\n",
      " 83%|████████▎ | 20/24 [00:02<00:00,  7.62it/s]SKIPPED _fit distribution (taking more than 30 seconds)\n",
      "Fitting 3 distributions: 100%|██████████| 3/3 [00:00<00:00, 18.30it/s]\n",
      " 88%|████████▊ | 21/24 [00:02<00:00,  7.04it/s]SKIPPED _fit distribution (taking more than 30 seconds)\n",
      "Fitting 3 distributions: 100%|██████████| 3/3 [00:00<00:00, 20.13it/s]\n",
      " 92%|█████████▏| 22/24 [00:02<00:00,  6.78it/s]SKIPPED _fit distribution (taking more than 30 seconds)\n",
      "Fitting 3 distributions: 100%|██████████| 3/3 [00:00<00:00, 19.77it/s]\n",
      " 96%|█████████▌| 23/24 [00:02<00:00,  6.56it/s]SKIPPED _fit distribution (taking more than 30 seconds)\n",
      "Fitting 3 distributions: 100%|██████████| 3/3 [00:00<00:00, 38.18it/s]\n",
      "100%|██████████| 24/24 [00:02<00:00,  8.21it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([0.00089223, 0.46333077,        nan]),\n",
       " array([0.00042777, 0.17386592,        nan]),\n",
       " array([0.07333744, 0.32837543,        nan]),\n",
       " array([1.90203316e-06, 2.84240166e-03,            nan]),\n",
       " array([2.24442977e-12, 1.36628546e-01,            nan]),\n",
       " array([6.40937038e-11, 2.53480719e-01,            nan]),\n",
       " array([2.45996920e-04, 6.25114049e-01,            nan]),\n",
       " array([5.68643081e-09, 3.38635672e-01,            nan]),\n",
       " array([3.36756643e-09, 5.72076620e-01,            nan]),\n",
       " array([7.80507712e-53, 8.45233375e-19,            nan]),\n",
       " array([2.40427150e-34, 9.53413609e-07,            nan]),\n",
       " array([1.20210672e-29, 6.92162825e-06,            nan]),\n",
       " array([3.78561317e-63, 2.35017243e-02,            nan]),\n",
       " array([1.99894717e-83, 3.91800486e-51,            nan]),\n",
       " array([1.57536446e-74, 1.64967840e-09,            nan]),\n",
       " array([2.72779449e-35, 1.01966754e-09,            nan]),\n",
       " array([1.71738182e-39, 7.88013988e-07,            nan]),\n",
       " array([1.58240580e-47, 1.97947855e-03,            nan]),\n",
       " array([0.00000000e+00, 6.53535215e-51,            nan]),\n",
       " array([2.88308439e-69, 3.10627559e-44,            nan]),\n",
       " array([1.97332537e-69, 1.54396526e-24,            nan]),\n",
       " array([5.08450058e-28, 1.01185758e-12,            nan]),\n",
       " array([1.87836608e-28, 1.87373589e-10,            nan]),\n",
       " array([0.00000000e+00, 3.16463334e-49,            nan])]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist_ks_values = []\n",
    "for tweets_hour in tqdm.tqdm(tweets_per_file):\n",
    "    dist_ks_values.append(get_fitted_summary(tweets_hour))\n",
    "\n",
    "dist_ks_values\n",
    "# np.concatenate(dist_ks_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.mean([i>=.01 for i in get_fitted_ks_values(stream_ln)])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "eacde64116501d434fc36353d8e421b6798d96015acf9f09cfdb6234af2c3678"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
